# Food101-ViT
<img src="./Assets/ViT.gif" width="500px"></img>
<a href='https://research.google/blog/transformers-for-image-recognition-at-scale/'><br> Src: Google Blog</a>
<br>
<img src="./Assets/Transformer-Encoder.png" width="300px"><br> The main Transformer encoder from <a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></img>
<br>
<img src="./Assets/Predictor.gif" width="500px"></img><br>
<a href='https://huggingface.co/spaces/eternalBlissard/FoodVision101'> My Model on Hugging Face</a>
<br>
I have done the training for my ViT on Food101 Dataset and deployed model can be used from <a href='https://huggingface.co/spaces/eternalBlissard/FoodVision101'> here</a> .
